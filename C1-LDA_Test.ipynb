{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projecting Reviews about the Host per Listing, per Year Based on the Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import and setup modules we'll be using in this notebook\n",
    "import logging\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import sys\n",
    "reload(sys)  \n",
    "import matplotlib.ticker as mtick\n",
    "import re\n",
    "import cPickle\n",
    "sys.setdefaultencoding('utf8')\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO  # ipython sometimes messes up the logging setup; restore\n",
    "from gensim.utils import smart_open, simple_preprocess\n",
    "from gensim.corpora.wikicorpus import _extract_pages, filter_wiki\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in vectorized corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(r\"corpus.pickle\", \"rb\") as input_file:\n",
    "    corpus= cPickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.039*\"arrived\" + 0.031*\"late\" + 0.025*\"flight\" + 0.018*\"arrival\" + 0.017*\"morning\" + 0.017*\"luggage\" + 0.016*\"greeted\" + 0.014*\"left\" + 0.014*\"breakfast\" + 0.013*\"early\"'),\n",
       " (1,\n",
       "  u'0.161*\"nyc\" + 0.033*\"alex\" + 0.027*\"chris\" + 0.024*\"sam\" + 0.022*\"john\" + 0.019*\"mike\" + 0.018*\"en\" + 0.018*\"exceeded\" + 0.017*\"anna\" + 0.015*\"exceeded_expectation\"'),\n",
       " (2,\n",
       "  u'0.070*\"subway\" + 0.053*\"close\" + 0.034*\"walk\" + 0.030*\"manhattan\" + 0.028*\"station\" + 0.026*\"minute\" + 0.026*\"train\" + 0.024*\"park\" + 0.024*\"away\" + 0.024*\"block\"'),\n",
       " (3,\n",
       "  u'0.035*\"easy\" + 0.026*\"check\" + 0.026*\"helpful\" + 0.025*\"question\" + 0.023*\"responsive\" + 0.019*\"accommodating\" + 0.016*\"communication\" + 0.014*\"needed\" + 0.014*\"meet\" + 0.013*\"time\"'),\n",
       " (4,\n",
       "  u'0.280*\"new\" + 0.232*\"york\" + 0.231*\"new_york\" + 0.020*\"city\" + 0.010*\"trip\" + 0.006*\"visit\" + 0.006*\"visiting\" + 0.005*\"julia\" + 0.005*\"consider\" + 0.005*\"jason\"'),\n",
       " (5,\n",
       "  u'0.032*\"wonderful\" + 0.032*\"home\" + 0.026*\"recommend\" + 0.025*\"feel\" + 0.024*\"amazing\" + 0.023*\"staying\" + 0.021*\"thank\" + 0.021*\"experience\" + 0.018*\"lovely\" + 0.016*\"perfect\"'),\n",
       " (6,\n",
       "  u'0.018*\"bed\" + 0.014*\"kitchen\" + 0.014*\"location\" + 0.011*\"towel\" + 0.011*\"use\" + 0.010*\"bathroom\" + 0.010*\"air\" + 0.010*\"central\" + 0.009*\"building\" + 0.009*\"bedroom\"'),\n",
       " (7,\n",
       "  u'0.069*\"nice\" + 0.050*\"friendly\" + 0.043*\"helpful\" + 0.031*\"welcoming\" + 0.026*\"time\" + 0.026*\"room\" + 0.026*\"good\" + 0.025*\"kind\" + 0.021*\"clean\" + 0.016*\"super\"'),\n",
       " (8,\n",
       "  u'0.167*\"roommate\" + 0.088*\"dog\" + 0.078*\"cat\" + 0.058*\"loft\" + 0.048*\"chance\" + 0.048*\"chance_meet\" + 0.033*\"meet\" + 0.032*\"adorable\" + 0.026*\"brother\" + 0.022*\"cute\"'),\n",
       " (9,\n",
       "  u'0.061*\"restaurant\" + 0.037*\"area\" + 0.037*\"recommendation\" + 0.027*\"local\" + 0.025*\"bar\" + 0.022*\"neighborhood\" + 0.021*\"eat\" + 0.019*\"shop\" + 0.017*\"location\" + 0.016*\"lot\"')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.LdaModel.load('lda1.pkl')\n",
    "#top_topics = model.top_topics(corpus, num_words=5)\n",
    "model.show_topics()\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "#avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "#print('Average topic coherence: %.4f.' % avg_topic_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics=[]\n",
    "top_topics=model.show_topics()\n",
    "for t in top_topics:\n",
    "    topic={}\n",
    "    for chunk in t[1].split('+'):\n",
    "        topic[chunk.split('*')[1].strip(\"'\")] = float(chunk.split('*')[0])\n",
    "    topics.append(topic)\n",
    "    \n",
    "from pprint import pprint\n",
    "#pprint(top_topics)\n",
    "df_list=[]\n",
    "\n",
    "for topic in topics:\n",
    "\n",
    "    df_= pd.DataFrame([(str(k),v) for k,v in topic.iteritems() ])\n",
    "    df_.sort_values([1], ascending=False)\n",
    "    \n",
    "    df_list.append( df_[0])\n",
    "\n",
    "df = pd.concat(df_list, axis = 1)\n",
    "df.columns=[ [ 'Topic'+str(i) for i in range(len(df_list))]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_text=pd.read_csv('../DataFiles/sentences_withPersonName_NYC_listing.csv')\n",
    "#df_text=df_text[df_text.year>2009]\n",
    "#df_=pd.DataFrame(df_text.groupby(['listing_id']).year.count())\n",
    "#indices=df_[df_.year==7].index.tolist()\n",
    "#df_text=df_text[df_text['listing_id'].isin(indices)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b09512894b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_text' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "num_topics= model.num_topics\n",
    "for i in range(num_topics):\n",
    "    df_text['topic'+str(i)]=0.0\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    topic_dist=model.get_document_topics(corpus[i])\n",
    "    if i % 1000 ==0:print i,'/',len(corpus)\n",
    "\n",
    "    for j in range(len(topic_dist)):\n",
    "        topic_no=topic_dist[j][0]\n",
    "        \n",
    "        df_text.set_value(i,'topic'+str(j) , topic_dist[j][1])\n",
    "        \n",
    "df_text.to_csv('../DataFiles/sentences_withPersonName_NYC_listing_topics.csv')       \n",
    "df_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_dist\n",
    "['year']+ ['topic'+str(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_year=df_text[['year']+ ['topic'+str(i) for i in range(10)]]\n",
    "df_year=df_year.groupby('year').mean()\n",
    "df_year.to_csv('../DataFiles/topicOverTimeNYC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chanages of contribution to each topic over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_year=pd.read_csv('../DataFiles/topicOverTimeNYC.csv')\n",
    " \n",
    "params = {'legend.fontsize': 8,}\n",
    "plt.rcParams['figure.figsize'] = 12,8\n",
    "f, axarr = plt.subplots(4,3)\n",
    "plt.subplots_adjust(hspace=1)\n",
    "\n",
    "plt.suptitle('Trends of Topics 2010-2016  in NYC\\\n",
    "             \\n(percentage of mentioning of each aspect in whole reviews)',fontsize=16)\n",
    "k=0\n",
    "x=range(2010,2017)\n",
    "for i in range(0,4):\n",
    "    for j in range(0,3):\n",
    "\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        if k>9: break\n",
    "        plt.rcParams.update(params)\n",
    "        y=df_year['topic'+str(k)]\n",
    "\n",
    "        axarr[i, j].plot(x, y)\n",
    "        axarr[i, j].set_title('topic'+str(k))\n",
    "      #  axarr[i, j].set_ylim(0,1)\n",
    "        axarr[i, j].get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "        axarr[i, j].yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2f'))\n",
    "        for tick in axarr[i, j].get_xaxis().get_major_ticks():\n",
    "\n",
    "            tick.label.set_fontsize(8) \n",
    "#            tick.label.set_rotation('vertical')\n",
    "\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
